{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNVK0xp3D3VUDiiPhnCde2X",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/thileshs/thileshLLM1/blob/main/RAG.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-JpLK2jp_o3m",
        "outputId": "2ae9740e-130f-4578-d05d-7af639fbf5a2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain-community\n",
            "  Downloading langchain_community-0.2.6-py3-none-any.whl (2.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m21.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (2.0.31)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (3.9.5)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Requirement already satisfied: langchain<0.3.0,>=0.2.6 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.2.6)\n",
            "Requirement already satisfied: langchain-core<0.3.0,>=0.2.10 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.2.11)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.1.84)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (1.25.2)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (2.31.0)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (8.4.2)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (4.0.3)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading marshmallow-3.21.3-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.2/49.2 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from langchain<0.3.0,>=0.2.6->langchain-community) (0.2.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain<0.3.0,>=0.2.6->langchain-community) (2.8.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.10->langchain-community) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.10->langchain-community) (24.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.0->langchain-community) (3.10.6)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (2024.6.2)\n",
            "Requirement already satisfied: typing-extensions>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community) (4.12.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.0.3)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.10->langchain-community) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain<0.3.0,>=0.2.6->langchain-community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain<0.3.0,>=0.2.6->langchain-community) (2.20.0)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: mypy-extensions, marshmallow, typing-inspect, dataclasses-json, langchain-community\n",
            "Successfully installed dataclasses-json-0.6.7 langchain-community-0.2.6 marshmallow-3.21.3 mypy-extensions-1.0.0 typing-inspect-0.9.0\n"
          ]
        }
      ],
      "source": [
        "pip install -U langchain-community"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "yV91KlOCLumi"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nMKArPQALvFJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "Z92g3Gz9BoXT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from langchain import PromptTemplate, LLMChain\n",
        "from PyPDF2 import PdfReader\n",
        "from langchain.embeddings import VertexAIEmbeddings\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.llms import VertexAI"
      ],
      "metadata": {
        "id": "Q7CViToSANVs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from PyPDF2 import PdfReader\n",
        "from langchain import PromptTemplate, LLMChain\n",
        "from langchain.llms import VertexAI\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "\n",
        "# Set Google Application Credentials\n",
        "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"/content/lumen-b-ctl-047-e2aeb24b0ea0 5 2.json\"\n",
        "\n",
        "# CSV and PDF file paths\n",
        "csv_path = \"/content/new_filtered 2.csv\"\n",
        "pdf_paths = [\n",
        "    '/content/Attempt to fetch past end of record - CST.CST_ACCOUNT 1.pdf',\n",
        "    '/content/Attempt to fetch past end of record - CST.CST_DAILY_CASHDRAWER 1.pdf',\n",
        "    '/content/Attempt to fetch past end of record 2.pdf',\n",
        "    '/content/Number area code not found 3.pdf',\n",
        "    '/content/The result of a singleton select returned more than 1 value (1) 2.pdf'\n",
        "]\n",
        "\n",
        "\n",
        "# Function to extract text from PDFs\n",
        "def extract_text_from_pdfs(pdf_paths):\n",
        "    raw_text = ''\n",
        "    for pdf_path in pdf_paths:\n",
        "        reader = PdfReader(pdf_path)\n",
        "        for page in reader.pages:\n",
        "            content = page.extract_text()\n",
        "            if content:\n",
        "                raw_text += content\n",
        "    return raw_text\n",
        "\n",
        "# Load the CSV file into a DataFrame with the specified encoding\n",
        "error_logs_df = pd.read_csv(csv_path, encoding='latin1')\n",
        "def should_drop(value):\n",
        "    return str(value).startswith('GT2') or str(value).startswith('GTW')\n",
        "\n",
        "# Drop rows where any of the specified columns start with 'GT2' or 'GTW'\n",
        "error_logs_df = error_logs_df[~(error_logs_df['Prog'].apply(should_drop) |\n",
        "                                error_logs_df['Program'].apply(should_drop) |\n",
        "                                error_logs_df['API'].apply(should_drop))]\n",
        "# Text processing from PDFs\n",
        "raw_text = extract_text_from_pdfs(pdf_paths)\n",
        "text_splitter = CharacterTextSplitter(separator=\"\\n\", chunk_size=800, chunk_overlap=200, length_function=len)\n",
        "texts = text_splitter.split_text(raw_text)\n",
        "\n",
        "# Template for generating prompts\n",
        "prompt_template = \"\"\"\n",
        "You are an AI assistant that summarizes error logs and provides resolutions. Here are some example resolutions extracted from a PDF:\n",
        "{pdf_text}\n",
        "\n",
        "---\n",
        "Read the PDF and analyze it. Now we have the dataframe error_logs_df with columns -\n",
        "[\"Log No\", \"Time\", \"Prog\", \"Program\", \"Section\", \"Prog Mess\", \"System messages\", \"Table\"].\n",
        "In that dataframe, the \"Prog Mess\" column has some values. Take those values and compare them with\n",
        "the issues available in the PDF.\n",
        "\n",
        "For each log, you must:\n",
        "    1. Check if the table data in the \"Table\" column matches any table mentioned in the PDF text.\n",
        "    2. If a match is found, provide a detailed resolution based on the table and the issue.\n",
        "    3. If no match is found, simply state \"No data found\".\n",
        "\n",
        "Now, given the following error log, provide a detailed resolution:\n",
        "\n",
        "Strictly print Only the log no, Error, issues,Table and resolution.\n",
        "Error: {error_id}\n",
        "Resolution: {error_description}\n",
        "\"\"\"\n",
        "\n",
        "# Function to generate prompt string\n",
        "def generate_prompt(pdf_text, error_id, error_description):\n",
        "    return prompt_template.format(pdf_text=pdf_text, error_id=error_id, error_description=error_description)\n",
        "\n",
        "# Initialize LLMChain with VertexAI language model\n",
        "llm_chain = LLMChain(\n",
        "    prompt=PromptTemplate(input_variables=[\"prompt\"], template=\"{prompt}\"),\n",
        "    llm=VertexAI(model_name=\"gemini-1.5-pro-preview-0409\", temperature=0.5, max_output_tokens=8192)\n",
        ")\n",
        "\n",
        "# Function to handle error logs and generate resolution\n",
        "def handle_error_log(error_id, error_description):\n",
        "    prompt_string = generate_prompt(raw_text, error_id, error_description)\n",
        "    generated_resolution = llm_chain.run({\"prompt\": prompt_string})\n",
        "    return generated_resolution\n",
        "\n",
        "# Iterate through each row in the DataFrame and print log details with resolution\n",
        "for index, row in error_logs_df.iterrows():\n",
        "    log_id = row['Log No']\n",
        "    error = row['Prog Mess']\n",
        "\n",
        "    # Check if log_id is null or blank\n",
        "    if pd.isna(log_id) or log_id == '':\n",
        "        print(f\"End of CSV reached at row {index}. Stopping further processing.\")\n",
        "        break\n",
        "\n",
        "    # Generate resolution for the current log entry\n",
        "    generated_resolution = handle_error_log(log_id, error)\n",
        "\n",
        "    # Print the formatted output\n",
        "    print(f\"Resolution for Log ID: {log_id}\\n{generated_resolution}\")\n",
        "    print(\"\\n---\\n\")\n",
        "    print(\"The Mail been sent to SUPPORT TEAM\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4HIeOCuxBuVo",
        "outputId": "90d3d7af-a943-485a-8480-133af666ced2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-16-ac91003f4085>:34: DtypeWarning: Columns (1,2,4,5,8,9,10,11,12,14,15,16,18) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  error_logs_df = pd.read_csv(csv_path, encoding='latin1')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Resolution for Log ID: 73007643.0\n",
            "Log no: 73007643.0\n",
            "Error: %RDB-E-STREAM_EOF, attempt to fetch past end of record stream\n",
            "Issues: Unable to sign off service  order\n",
            "Table: CST.CST_ACCOUNT \n",
            "Resolution: This resolution is for CST.CST_ACCOUNT Table associated with Attempt to fetch past end of record. There is some data mismatch or unavailable in the database. \n",
            "\n",
            "\n",
            "---\n",
            "\n",
            "The Mail been sent to SUPPORT TEAM\n",
            "Resolution for Log ID: 73007644.0\n",
            "Log No: 73007644.0\n",
            "Error: %RDB-E-STREAM_EOF, attempt to fetch past end of record stream\n",
            "Issues: Unable to sign off service order\n",
            "Table: CST.CST_ACCOUNT \n",
            "Resolution: This resolution is for CST.CST_ACCOUNT Table associated with Attempt to fetch past end of record. There is some data mismatch or unavailable in the database. \n",
            "\n",
            "\n",
            "---\n",
            "\n",
            "The Mail been sent to SUPPORT TEAM\n",
            "Resolution for Log ID: 73007645.0\n",
            "Log No: 73007645.0\n",
            "Error: %RDB-E-STREAM_EOF, attempt to fetch past end of record stream\n",
            "Issues: Unable to sign off service order\n",
            "Table: CST.CST_ACCOUNT \n",
            "Resolution: This resolution is for CST.CST_ACCOUNT Table associated with Attempt to fetch past end of record. There is some data mismatch or unavailable in the database. \n",
            "\n",
            "\n",
            "---\n",
            "\n",
            "The Mail been sent to SUPPORT TEAM\n",
            "Resolution for Log ID: 73007646.0\n",
            "Log no: 73007646.0\n",
            "Error: %SQL-F-SELMORVAL, The result of a singleton select returned more than 1 value\n",
            "Issues: Unable to sign off  GN4974I from the billing department\n",
            "Table: CST_SERVICE\n",
            "Resolution: Have amended the SER_ADSL_UNIQUE_SERV_ID from 31494388 to \"   \". \n",
            "\n",
            "\n",
            "---\n",
            "\n",
            "The Mail been sent to SUPPORT TEAM\n",
            "Resolution for Log ID: 73007647.0\n",
            "Log No: 73007647.0\n",
            "Error: %RDB-E-NO_DUP, index field value already exists; duplicates not allowed for CST_EMR_STATUS_SU\n",
            "Issues: No data found\n",
            "Table: CST_EMR_STATUS_SU\n",
            "Resolution: No data found \n",
            "\n",
            "\n",
            "---\n",
            "\n",
            "The Mail been sent to SUPPORT TEAM\n",
            "Resolution for Log ID: 73007648.0\n",
            "Log No: 72856523.0\n",
            "Error: Number area code not found: SORD\n",
            "Issues: Unable to sign off service order\n",
            "Table: No data found\n",
            "Resolution: Need to notify the BU users saying that there are no services associated with the respective area \n",
            "code to generate the user report.  Also need to notify the configuration team if the users rai se the ticket to configure the new number \n",
            "series for the given number area code. \n",
            "\n",
            "\n",
            "---\n",
            "\n",
            "The Mail been sent to SUPPORT TEAM\n",
            "End of CSV reached at row 9. Stopping further processing.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tP4CE785rEsC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "swB4TwLorFJ-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from langchain import PromptTemplate, LLMChain\n",
        "from PyPDF2 import PdfReader\n",
        "from langchain.embeddings import VertexAIEmbeddings\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.llms import VertexAI\n",
        "\n",
        "\n",
        "\n",
        "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = '/content/lumen-b-ctl-047-e2aeb24b0ea0 5 2.json'\n",
        "\n",
        "\n",
        "\n",
        "# Load CSV and process dataframe\n",
        "csv_path = \"/content/new_filtered 2.csv\"\n",
        "error_logs_df = pd.read_csv(csv_path)\n",
        "\n",
        "\n",
        "def should_drop(value):\n",
        "    return str(value).startswith('GT2') or str(value).startswith('GTW')\n",
        "\n",
        "\n",
        "\n",
        "error_logs_df = error_logs_df[~(error_logs_df['Prog'].apply(should_drop) |\n",
        "                                error_logs_df['Program'].apply(should_drop) |\n",
        "                                error_logs_df['API'].apply(should_drop))]\n",
        "\n",
        "\n",
        "\n",
        "# Load and process PDF files\n",
        "pdf_paths = [\n",
        "    '/content/Attempt to fetch past end of record - CST.CST_ACCOUNT 1.pdf',\n",
        "    '/content/Attempt to fetch past end of record - CST.CST_DAILY_CASHDRAWER 1.pdf',\n",
        "    '/content/Attempt to fetch past end of record 2.pdf',\n",
        "    '/content/Number area code not found 3.pdf',\n",
        "    '/content/The result of a singleton select returned more than 1 value (1) 2.pdf'\n",
        "]\n",
        "\n",
        "\n",
        "\n",
        "raw_text = ''\n",
        "for pdf_path in pdf_paths:\n",
        "    reader = PdfReader(pdf_path)\n",
        "    for page in reader.pages:\n",
        "        content = page.extract_text()\n",
        "        if content:\n",
        "            raw_text += content\n",
        "\n",
        "\n",
        "\n",
        "# Split text into chunks\n",
        "text_splitter = CharacterTextSplitter(\n",
        "    separator=\"\\n\",\n",
        "    chunk_size=2000,\n",
        "    chunk_overlap=2,\n",
        "    length_function=len,\n",
        ")\n",
        "texts = text_splitter.split_text(raw_text)\n",
        "\n",
        "\n",
        "\n",
        "# Create embeddings and FAISS index\n",
        "embeddings = VertexAIEmbeddings()\n",
        "document_search = FAISS.from_texts(texts, embeddings)\n",
        "\n",
        "\n",
        "\n",
        "# Define the prompt template\n",
        "prompt_template = \"\"\"\n",
        "You are an AI assistant that summarizes error logs and provides resolutions. Here are some example resolutions extracted from a PDF:\n",
        "\n",
        "\n",
        "\n",
        "{pdf_text}\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "Read the PDF and analyze it. Now we have the dataframe `error_logs_df` with columns -\n",
        "[\"Log No\", \"Time\", \"Prog\", \"Program\", \"Section\", \"Prog Mess\", \"System messages\", \"Table\"].\n",
        "In that dataframe, the \"Prog Mess\" column has some values. Take those values and compare them with\n",
        "the issues available in the PDF.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Now, given the following error log, provide a detailed resolution:\n",
        "\n",
        "\n",
        "\n",
        "Strictly print Only the table,Error, issues, and resolution.\n",
        "Error: {error_id}\n",
        "Resolution: {error_description}\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "\n",
        "# Generate the prompt\n",
        "def generate_prompt(pdf_text, error_id, error_description):\n",
        "    return prompt_template.format(pdf_text=pdf_text, error_id=error_id, error_description=error_description)\n",
        "\n",
        "\n",
        "\n",
        "template = PromptTemplate(input_variables=[\"prompt\"], template=\"{prompt}\")\n",
        "llm_chain = LLMChain(prompt=template, llm=VertexAI(temperature=0.7))\n",
        "\n",
        "\n",
        "\n",
        "# Handle each error log and find resolution using document search\n",
        "def handle_error_log(error_id, error_description):\n",
        "    # Use document search to find the most relevant text chunks from the PDFs\n",
        "    results = document_search.similarity_search(error_description, k=3)\n",
        "    relevant_text = \"\\n\".join([result.page_content for result in results])\n",
        "\n",
        "\n",
        "\n",
        "    # Generate the prompt with the relevant text\n",
        "    prompt_string = generate_prompt(relevant_text, error_id, error_description)\n",
        "    generated_resolution = llm_chain.run({\"prompt\": prompt_string})\n",
        "    return generated_resolution\n",
        "\n",
        "\n",
        "\n",
        "for index, row in error_logs_df.iterrows():\n",
        "    error_id = row['Log No']\n",
        "    error_description = row['Prog Mess']\n",
        "\n",
        "    # Check if log number is null or NaN\n",
        "    if pd.isnull(error_id) or error_id == '':\n",
        "        print(\"Log No is null or NaN. Stopping the iteration.\")\n",
        "        break\n",
        "\n",
        "    resolution = handle_error_log(error_id, error_description)\n",
        "    print(f\"Resolution for Log ID {error_id}:\\n\", resolution)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SVo-aYT9CXbJ",
        "outputId": "18e5b08e-c505-4170-b834-f9e7ae05055b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-17-805f7cc8887a>:18: DtypeWarning: Columns (1,2,4,5,8,9,10,11,12,14,15,16,18) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  error_logs_df = pd.read_csv(csv_path)\n",
            "WARNING:langchain_community.embeddings.vertexai:Model_name will become a required arg for VertexAIEmbeddings starting from Feb-01-2024. Currently the default is set to textembedding-gecko@001\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Resolution for Log ID 73007643.0:\n",
            "  | Table | Error | Issues | Resolution |\n",
            "|---|---|---|---|\n",
            "| CST.CST_ACCOUNT | 73007643.0 | Unable to sign off service order | This resolution is for CST_Account Table associated with Attempt to fetch past end of record. There is some data mismatch or unavailable in database. |\n",
            "| CST.CST_DAILY_CASHDRAWER | 73007643.0 | Unable to sign off service order | This resolution is for CST. CST_DAILY_CASHDRAWER Table associated with Attempt to fetch past end of record. There is some data\n",
            "Resolution for Log ID 73007644.0:\n",
            "  | Table | Error | Issue | Resolution |\n",
            "|---|---|---|---|\n",
            "| CST.CST_ACCOUNT | Attempt to fetch past end of record | Unable to sign off service order | This resolution is for CST_Account Table associated with Attempt to fetch past end of record. There is some data mismatch or unavailable in database. |\n",
            "| CST. CST_DAILY_CASHDRAWER | Attempt to fetch past end of record | Unable to sign off service order | This resolution is for CST. CST_DAILY_CASHDRAWER Table associated with Attempt to fetch past end of record. There is some data mismatch or unavailable in database. |\n",
            "\n",
            "Resolution for Log ID 73007645.0:\n",
            "  **Table: CST.CST_DAILY_CASHDRAWER**\n",
            "\n",
            "**Error:** Attempt to fetch past end of record stream\n",
            "\n",
            "**Issue:** Unable to sign off service order\n",
            "\n",
            "**Resolution:** This resolution is for CST.CST_DAILY_CASHDRAWER Table associated with Attempt to fetch past end of record. There is some data mismatch or unavailable in the database.\n",
            "Resolution for Log ID 73007646.0:\n",
            "  | Table | Error | Issue | Resolution |\n",
            "| ----------- | ----------- | ----------- | ----------- |\n",
            "| Not Provided | 73007646.0 | %SQL-F-SELMORVAL, The result of a singleton select returned more than 1 value | Not Provided |\n",
            "Resolution for Log ID 73007647.0:\n",
            "  **Table:** CST_EMR_STATUS_SU\n",
            "\n",
            "**Error:** %RDB-E-NO_DUP, index field value already exists; duplicates not allowed\n",
            "\n",
            "**Issue:** Unable to insert a new record into the CST_EMR_STATUS_SU table due to a duplicate index field value.\n",
            "\n",
            "**Resolution:** Identify the existing record with the duplicate index field value and take appropriate action, such as updating the existing record or merging the data from the new record into the existing record.\n",
            "Resolution for Log ID 73007648.0:\n",
            "  | Error | Issue | Resolution |\n",
            "|---|---|---|\n",
            "| 73007648.0 | Unable to generate user report | Need to notify the BU users saying that there are no services associated with the respective area code to generate the user report. Also need to notify the configuration team if the users raise the ticket to configure the new number series for the given number area code. |\n",
            "Log No is null or NaN. Stopping the iteration.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install faiss-cpu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j7vgLoa3DWe6",
        "outputId": "d1f2e9e0-ff69-4bd5-8e81-0a9646f16e6a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting faiss-cpu\n",
            "  Downloading faiss_cpu-1.8.0.post1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (27.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.0/27.0 MB\u001b[0m \u001b[31m32.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from faiss-cpu) (1.25.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from faiss-cpu) (24.1)\n",
            "Installing collected packages: faiss-cpu\n",
            "Successfully installed faiss-cpu-1.8.0.post1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VArfOxMbDavV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}